{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bYniTY18yHx2"
   },
   "source": [
    "# StreamBasedCache Demo - New York Taxi Rides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "RUtedcvxeXG1"
   },
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "yFU0y74LKkZz"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    GOOGLE_COLAB = True\n",
    "except ImportError:\n",
    "    GOOGLE_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "vwc8s3ZMviEy"
   },
   "outputs": [],
   "source": [
    "if GOOGLE_COLAB:\n",
    "    !sudo apt-get -yqq install libsnappy-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "6JBBvTSgvcoD"
   },
   "outputs": [],
   "source": [
    "if GOOGLE_COLAB:\n",
    "    !pip install -q python-snappy Faker pyproj\n",
    "    !pip install -q -U bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9938,
     "status": "ok",
     "timestamp": 1561509815353,
     "user": {
      "displayName": "Alexey Strokach",
      "photoUrl": "https://lh4.googleusercontent.com/-CsQDBBcl3n0/AAAAAAAAAAI/AAAAAAAACyg/LJXILPSVwok/s64/photo.jpg",
      "userId": "14295043229009166910"
     },
     "user_tz": 420
    },
    "hidden": true,
    "id": "zsUWt2AjsmWU",
    "outputId": "b2f917a3-9f89-4317-8a40-4e501de2415d"
   },
   "outputs": [],
   "source": [
    "if GOOGLE_COLAB:\n",
    "    !pip install \"git+https://github.com/ostrokach/beam.git@feature/streambasedcache#egg=apache_beam[gcp]&subdirectory=sdks/python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5zc3pwq0smN-"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EwceiH15eVt-"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "import uuid\n",
    "from collections import Counter, OrderedDict\n",
    "from datetime import datetime\n",
    "\n",
    "import apache_beam as beam\n",
    "import bokeh\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pytz\n",
    "import requests\n",
    "import tqdm\n",
    "from apache_beam.io.filesystems import FileSystems\n",
    "from apache_beam.io.gcp.pubsub import PubsubMessage\n",
    "from apache_beam.options.pipeline_options import (GoogleCloudOptions,\n",
    "                                                  PipelineOptions)\n",
    "from apache_beam.runners.direct.direct_runner import BundleBasedDirectRunner\n",
    "from apache_beam.runners.interactive import caching\n",
    "from apache_beam.runners.interactive.caching import streambasedcache\n",
    "from apache_beam.transforms import combiners, window\n",
    "from apache_beam.transforms.ptransform import ptransform_fn\n",
    "from bokeh.core.properties import value\n",
    "from bokeh.io import output_notebook, push_notebook, show\n",
    "from bokeh.layouts import row\n",
    "from bokeh.models import (ColumnDataSource, Label, LabelSet, Legend,\n",
    "                          LegendItem, Range1d)\n",
    "from bokeh.models.annotations import Title\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.tile_providers import Vendors, get_provider\n",
    "from bokeh.transform import factor_cmap, factor_mark\n",
    "from faker import Faker\n",
    "from google.api_core import exceptions as gexc\n",
    "from google.cloud import pubsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hzzEnIEftMYZ"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GOOGLE_COLAB:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10345,
     "status": "ok",
     "timestamp": 1561509815816,
     "user": {
      "displayName": "Alexey Strokach",
      "photoUrl": "https://lh4.googleusercontent.com/-CsQDBBcl3n0/AAAAAAAAAAI/AAAAAAAACyg/LJXILPSVwok/s64/photo.jpg",
      "userId": "14295043229009166910"
     },
     "user_tz": 420
    },
    "id": "IpuqYM-zsorD",
    "outputId": "28d072f4-bafc-483f-98e3-931be526e177"
   },
   "outputs": [],
   "source": [
    "#@title Google Cloud Project Info { display-mode: \"form\" }\n",
    "project_id = \"strokach-playground\" #@param {type:\"string\"}\n",
    "gcs_temp_location = \"gs://strokach/dataflow_temp\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_NAME = \"streambasedcache-new_york_taxirides_from_file\"\n",
    "try:\n",
    "    os.mkdir(NOTEBOOK_NAME)\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10315,
     "status": "ok",
     "timestamp": 1561509815817,
     "user": {
      "displayName": "Alexey Strokach",
      "photoUrl": "https://lh4.googleusercontent.com/-CsQDBBcl3n0/AAAAAAAAAAI/AAAAAAAACyg/LJXILPSVwok/s64/photo.jpg",
      "userId": "14295043229009166910"
     },
     "user_tz": 420
    },
    "id": "Y2KieHGYrOKY",
    "outputId": "3ed360d6-651a-4477-eb12-5a7cab5bd4c8"
   },
   "outputs": [],
   "source": [
    "options = PipelineOptions(\n",
    "    temp_location=gcs_temp_location, streaming=True, project=project_id\n",
    ")\n",
    "options.display_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "except Exception:\n",
    "    print(\"No autoreload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"new_york_taxirides_to_events/new-york-taxi-events.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = pq.read_table(input_file).to_pandas(integer_object_nulls=True)\n",
    "events_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JHv-dElW8IN9"
   },
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERCATOR_X_RANGE = (-8240000, -8220000)\n",
    "MERCATOR_Y_RANGE = (4950000, 5000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Basic bokeh plot using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "seconds_per_batch = 15 * 60  # 15 minutes\n",
    "events_df[\"group_id\"] = (\n",
    "    (events_df[\"timestamp_milliseconds\"] / 1000)\n",
    "    // seconds_per_batch\n",
    "    * seconds_per_batch\n",
    ").astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if GOOGLE_COLAB:\n",
    "    print(\"Interactive plot does not work on colab yet!\")\n",
    "\n",
    "\n",
    "def create_map():\n",
    "    # Colormap\n",
    "    # cmap = bokeh.palettes.d3[\"Category10\"][4]\n",
    "    cmap = bokeh.palettes.d3[\"Category20b\"][20]\n",
    "    colors = [cmap[1], cmap[-2]]\n",
    "\n",
    "    # Source of data\n",
    "    source = ColumnDataSource(data=dict(x=[], y=[], event_type=[]))\n",
    "\n",
    "    # Background map\n",
    "    fg = figure(\n",
    "        x_range=MERCATOR_X_RANGE,\n",
    "        y_range=MERCATOR_Y_RANGE,\n",
    "        x_axis_type=\"mercator\",\n",
    "        y_axis_type=\"mercator\",\n",
    "        title_location=\"above\",\n",
    "        plot_height=600,\n",
    "    )\n",
    "    fg.add_tile(get_provider(Vendors.CARTODBPOSITRON))\n",
    "\n",
    "    # Scatterplot\n",
    "    fg.circle(\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        source=source,\n",
    "        size=2,\n",
    "        color=factor_cmap(\"event_type\", colors, [\"start\", \"stop\"]),\n",
    "        fill_alpha=0.8,\n",
    "        #     legend=value(\"start\", \"stop\"),\n",
    "        #     legend=[value(x) for x in [\"start\", \"stop\"]],\n",
    "    )\n",
    "\n",
    "    # Legend\n",
    "    start = fg.circle(x=[], y=[], color=colors[0])\n",
    "    stop = fg.circle(x=[], y=[], color=colors[1])\n",
    "    legend = Legend(items=[(\"start\", [start]), (\"stop\", [stop])])\n",
    "    fg.add_layout(legend)\n",
    "    return fg, source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "\n",
    "fg, source = create_map()\n",
    "\n",
    "# Updates\n",
    "handle = show(fg, notebook_handle=True)\n",
    "\n",
    "days_of_week = [\n",
    "    \"Monday\",\n",
    "    \"Tuesday\",\n",
    "    \"Wednesday\",\n",
    "    \"Thursday\",\n",
    "    \"Friday\",\n",
    "    \"Saturday\",\n",
    "    \"Sunday\",\n",
    "]\n",
    "for index, gp in events_df.sample(frac=0.1).groupby([\"group_id\"]):\n",
    "    dt = datetime.utcfromtimestamp(index).replace(\n",
    "        tzinfo=pytz.UTC\n",
    "    )  # .astimezone(pytz.timezone('US/Eastern'))\n",
    "    dt_str = days_of_week[dt.weekday()] + \" \" + dt.strftime(\"%b %d %Y %I:%M:%S %p\")\n",
    "    fg.title.text = dt_str\n",
    "    fg.title.align = \"center\"\n",
    "    source.data = {\n",
    "        \"x\": gp[\"utm_x\"].values,\n",
    "        \"y\": gp[\"utm_y\"].values,\n",
    "        \"event_type\": gp[\"event_type\"].values,\n",
    "    }\n",
    "    push_notebook(handle=handle)\n",
    "    time.sleep(0.2)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write dataset to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df_sample = events_df.sample(frac=0.1).sort_values(\"timestamp_milliseconds\", ascending=True).head(100)\n",
    "events_df_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cache(location, cache_class, *args, **kwargs):\n",
    "    for _ in range(3):\n",
    "        full_location = \"{}-{}\".format(location, uuid.uuid4().hex)\n",
    "        try:\n",
    "            return cache_class(full_location, *args, **kwargs)\n",
    "        except IOError as e:\n",
    "            pass\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = create_cache(\n",
    "    \"projects/{}/topics/input\".format(project_id),\n",
    "    streambasedcache.PubSubBasedCache,\n",
    "#     with_attributes=[\"timestamp_milliseconds\"],\n",
    "#     timestamp_attribute=\"timestamp_milliseconds\",\n",
    ")\n",
    "\n",
    "cache.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /tmp/pipeline-gc-test3-00000-of-00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.write((c for c in string.ascii_letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string.ascii_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = PipelineOptions(\n",
    "    temp_location=gcs_temp_location, streaming=True, project=project_id,\n",
    "    runner=\"DirectRunner\",\n",
    "    runner=\"DataflowRunner\",\n",
    "    sdk_location=os.path.expanduser(\n",
    "        \"~/workspace/beam/sdks/python/dist/apache-beam-2.15.0.dev0.tar.gz\"\n",
    "    ),\n",
    "    setup_file=\"../setup.py\"\n",
    ")\n",
    "options.display_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options.display_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormatDoFn(beam.DoFn):\n",
    "    def process(self, element, window=beam.DoFn.WindowParam):\n",
    "        import pytz\n",
    "\n",
    "#         ts_format = \"%Y-%m-%dT%H:%M:%S.%f-04:00\"\n",
    "#         window_start = (\n",
    "#             window.start.to_utc_datetime()\n",
    "#             .replace(tzinfo=pytz.UTC)\n",
    "#             .astimezone(pytz.timezone(\"US/Eastern\"))\n",
    "#             .strftime(ts_format)\n",
    "#         )\n",
    "#         window_end = (\n",
    "#             window.end.to_utc_datetime()\n",
    "#             .replace(tzinfo=pytz.UTC)\n",
    "#             .astimezone(pytz.timezone(\"US/Eastern\"))\n",
    "#             .strftime(ts_format)\n",
    "#         )\n",
    "        yield {\n",
    "            \"events\": element,\n",
    "#             \"window_start\": window_start,\n",
    "#             \"window_end\": window_end,\n",
    "            \"window_start_milliseconds\": int(window.start.micros / 1000),\n",
    "            \"window_end_milliseconds\": int(window.end.micros / 1000)\n",
    "        }\n",
    "\n",
    "\n",
    "# next(FormatDoFn().process({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /tmp/pipeline-gc-test3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /tmp/pipeline-gc-test3-00000-of-00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apache_beam.utils.timestamp import Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexAssigningStatefulDoFn(beam.DoFn):\n",
    "    INDEX_STATE = beam.transforms.userstate.CombiningValueStateSpec(\"index\", sum)\n",
    "\n",
    "    def process(self, element, index=beam.DoFn.StateParam(INDEX_STATE)):\n",
    "        unused_key, value = element\n",
    "#         value = element\n",
    "        current_index = index.read()\n",
    "        yield (value, current_index)\n",
    "        index.add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_letters = string.ascii_letters[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.now().strftime(\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with beam.Pipeline(options=options) as p:\n",
    "    pcoll = (\n",
    "        p\n",
    "        | cache.reader()\n",
    "        | beam.Map(lambda e: time.sleep(0.5) or beam.window.TimestampedValue(e, Timestamp(seconds=int(reversed_letters = string.ascii_letters[::-1]))))\n",
    "#         | beam.Map(lambda e: beam.window.TimestampedValue(e, Timestamp(seconds=int(e))))\n",
    "        | beam.Map(lambda e: (0, e))\n",
    "        | beam.ParDo(IndexAssigningStatefulDoFn())\n",
    "        | beam.WindowInto(window.FixedWindows(0.5))\n",
    "        | beam.ParDo(FormatDoFn())\n",
    "        | beam.Map(lambda e: print(e) or e)\n",
    "#         | beam.ParDo(AddTimestampDoFn())\n",
    "        | beam.io.WriteToText(os.path.join(\"/tmp\", \"pipeline-gc-test3\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(cache.read(timeout=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Asdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.write((tup._asdict() for tup in events_df_sample.itertuples()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_source = cache.read(return_timestamp=True)\n",
    "time.sleep(5)\n",
    "[m for m in itertools.islice(cache_source, 5) if not time.sleep(1)]\n",
    "del cache_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data from subscription to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Limit(beam.PTransform):\n",
    "    def __init__(self, num_elements=1000):\n",
    "        self.num_elements = num_elements\n",
    "\n",
    "    def expand(self, pcoll):\n",
    "        from apache_beam import transforms\n",
    "        from apache_beam.transforms import combiners\n",
    "\n",
    "        return (\n",
    "            pcoll\n",
    "            | combiners.Sample.FixedSizeGlobally(self.num_elements)\n",
    "            | transforms.FlatMap(lambda lst: [e for e in lst])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToList(beam.PTransform):\n",
    "    \"\"\"A global CombineFn that condenses a PCollection into a single list.\"\"\"\n",
    "\n",
    "    def __init__(self, label=\"ToList\"):  # pylint: disable=useless-super-delegation\n",
    "        super(ToList, self).__init__(label)\n",
    "\n",
    "    def expand(self, pcoll):\n",
    "        return (\n",
    "            pcoll\n",
    "            | self.label\n",
    "            >> beam.CombineGlobally(combiners.ToListCombineFn()).without_defaults()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildRecordFn(beam.DoFn):\n",
    "    def __init__(self):\n",
    "        super(BuildRecordFn, self).__init__()\n",
    "\n",
    "    def process(self, elements, window=beam.DoFn.WindowParam):\n",
    "        # window_start = window.start.to_utc_datetime()\n",
    "        window_end = window.end.to_utc_datetime()\n",
    "        return [(window_end, elements)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormatMessage(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        from apache_beam.utils import timestamp\n",
    "        from apache_beam.transforms import window\n",
    "\n",
    "        data = element.data\n",
    "        ts = timestamp.Timestamp(micros=int(data[\"timestamp_milliseconds\"]) * 1000)\n",
    "        yield beam.window.TimestampedValue(data, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddTimestampAttribute(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        from apache_beam.io.gcp.pubsub import PubsubMessage\n",
    "\n",
    "        message = PubsubMessage(\n",
    "            data=element,\n",
    "            attributes={\"timestamp_milliseconds\": str(element[0][\"timestamp_milliseconds\"])},\n",
    "        )\n",
    "        yield message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormatDoFn(beam.DoFn):\n",
    "    def process(self, element, window=beam.DoFn.WindowParam):\n",
    "        import pytz\n",
    "\n",
    "        ts_format = \"%Y-%m-%dT%H:%M:%S.%f-04:00\"\n",
    "        window_start = (\n",
    "            window.start.to_utc_datetime()\n",
    "            .replace(tzinfo=pytz.UTC)\n",
    "            .astimezone(pytz.timezone(\"US/Eastern\"))\n",
    "            .strftime(ts_format)\n",
    "        )\n",
    "        window_end = (\n",
    "            window.end.to_utc_datetime()\n",
    "            .replace(tzinfo=pytz.UTC)\n",
    "            .astimezone(pytz.timezone(\"US/Eastern\"))\n",
    "            .strftime(ts_format)\n",
    "        )\n",
    "        yield {\n",
    "            \"events\": element,\n",
    "            \"window_start\": window_start,\n",
    "            \"window_end\": window_end,\n",
    "            \"timestamp_milliseconds\": element[0][\"timestamp_milliseconds\"],\n",
    "            \"window_end_milliseconds\": int(window.end.micros / 1000)\n",
    "        }\n",
    "\n",
    "\n",
    "# next(FormatDoFn().process({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddWindowRange(beam.DoFn):\n",
    "    def process(self, element, window=beam.DoFn.WindowParam):\n",
    "        import pytz\n",
    "\n",
    "        ts_format = \"%Y-%m-%dT%H:%M:%S.%f-04:00\"\n",
    "        element[\"window_start_est\"] = (\n",
    "            window.start.to_utc_datetime()\n",
    "            .replace(tzinfo=pytz.UTC)\n",
    "            .astimezone(pytz.timezone(\"US/Eastern\"))\n",
    "            .strftime(ts_format)\n",
    "        )\n",
    "        element[\"window_end_est\"] = (\n",
    "            window.end.to_utc_datetime()\n",
    "            .replace(tzinfo=pytz.UTC)\n",
    "            .astimezone(pytz.timezone(\"US/Eastern\"))\n",
    "            .strftime(ts_format)\n",
    "        )\n",
    "        element[\"window_start_milliseconds\"] = int(window.start.micros / 1000)\n",
    "        element[\"window_end_milliseconds\"] = int(window.end.micros / 1000)\n",
    "        yield element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pr.cancel()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "temp = create_cache(\n",
    "    \"projects/{}/topics/temp\".format(project_id),\n",
    "    streambasedcache.PubSubBasedCache,\n",
    "    with_attributes=[\"timestamp_milliseconds\"],\n",
    "    timestamp_attribute=\"timestamp_milliseconds\",\n",
    ")\n",
    "\n",
    "p = beam.Pipeline(runner=BundleBasedDirectRunner(), options=options)\n",
    "\n",
    "head = ()\n",
    "input = cache\n",
    "\n",
    "out_pcoll = (\n",
    "    p\n",
    "    | \"Read\" >> input.reader()  # Ideally, we could limit input a the reader level\n",
    "    #     | \"Limit\" >> Limit(100)  # Does not work?!!!\n",
    "    | \"Extract data\" >> beam.ParDo(FormatMessage())\n",
    "    | \"Window\" >> beam.WindowInto(window.FixedWindows(15 * 60))\n",
    "    | \"Add window info\" >> beam.ParDo(AddWindowRange())\n",
    "    | \"Pair with end of window\" >> beam.Map(lambda e: (e[\"window_end_milliseconds\"], e))\n",
    "    | \"Group by end of window\" >> beam.GroupByKey()\n",
    "    | \"Reduce\" >> beam.Map(lambda e: {\"timestamp_milliseconds\": e[0], \"events\": e[1]})\n",
    "    | \"Write\" >> temp.writer()\n",
    ")\n",
    "# Explicitly specify dependencies so that cache is not automatically garbage collected\n",
    "# out._deps = [cache]\n",
    "\n",
    "pr = p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_source  = temp.read(timeout=10, return_timestamp=True)\n",
    "# out = list(itertools.islice(data_source, 3))\n",
    "# out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg, source = create_map()\n",
    "fg.title.text = \"-\"\n",
    "fg.title.align = \"center\"\n",
    "\n",
    "# Updates\n",
    "handle = show(fg, notebook_handle=True)\n",
    "\n",
    "days_of_week = [\n",
    "    \"Monday\",\n",
    "    \"Tuesday\",\n",
    "    \"Wednesday\",\n",
    "    \"Thursday\",\n",
    "    \"Friday\",\n",
    "    \"Saturday\",\n",
    "    \"Sunday\",\n",
    "]\n",
    "\n",
    "data_source = temp.read(timeout=5, with_attributes=[\"timestamp_milliseconds\"], return_timestamp=True)\n",
    "time.sleep(2)\n",
    "\n",
    "for timestamp, message in data_source:\n",
    "    data = message.data[\"events\"]\n",
    "    dt = datetime.utcfromtimestamp(timestamp).replace(\n",
    "        tzinfo=pytz.UTC\n",
    "    )  # .astimezone(pytz.timezone('US/Eastern'))\n",
    "    dt_str = days_of_week[dt.weekday()] + \" \" + dt.strftime(\"%b %d %Y %I:%M:%S %f\")\n",
    "    fg.title.text = dt_str\n",
    "    fg.title.align = \"center\"\n",
    "    source.data = {\n",
    "        \"x\": [d[\"utm_x\"] for d in data],\n",
    "        \"y\": [d[\"utm_y\"] for d in data],\n",
    "        \"event_type\": [d[\"event_type\"] for d in data],\n",
    "    }\n",
    "    push_notebook(handle=handle)\n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg, source = create_map()\n",
    "fg.title.text = \"-\"\n",
    "fg.title.align = \"center\"\n",
    "\n",
    "# Updates\n",
    "handle = show(fg, notebook_handle=True)\n",
    "\n",
    "days_of_week = [\n",
    "    \"Monday\",\n",
    "    \"Tuesday\",\n",
    "    \"Wednesday\",\n",
    "    \"Thursday\",\n",
    "    \"Friday\",\n",
    "    \"Saturday\",\n",
    "    \"Sunday\",\n",
    "]\n",
    "\n",
    "data_source = temp.read(timeout=5, return_timestamp=True)\n",
    "time.sleep(5)\n",
    "\n",
    "current_batch = {\"timestamp\": None, \"utm_x\": [], \"utm_y\": [], \"event_type\": []}\n",
    "for timestamp, message in data_source:\n",
    "    data = message.data[\"events\"]\n",
    "    if current_batch[\"timestamp\"] is None or current_batch[\"timestamp\"] == timestamp:\n",
    "        current_batch[\"timestamp\"] = timestamp\n",
    "        current_batch[\"utm_x\"] += [d[\"utm_x\"] for d in data]\n",
    "        current_batch[\"utm_y\"] += [d[\"utm_y\"] for d in data]\n",
    "        current_batch[\"event_type\"] += [d[\"event_type\"] for d in data]\n",
    "        continue\n",
    "    elif current_batch[\"timestamp\"] > timestamp:\n",
    "        continue\n",
    "    else:\n",
    "        dt = datetime.utcfromtimestamp(timestamp).replace(\n",
    "            tzinfo=pytz.UTC\n",
    "        )  # .astimezone(pytz.timezone('US/Eastern'))\n",
    "        dt_str = days_of_week[dt.weekday()] + \" \" + dt.strftime(\"%b %d %Y %I:%M:%S %f\")\n",
    "        fg.title.text = dt_str\n",
    "        fg.title.align = \"center\"\n",
    "        source.data = {\n",
    "            \"x\": current_batch[\"utm_x\"],\n",
    "            \"y\": current_batch[\"utm_y\"],\n",
    "            \"event_type\": current_batch[\"event_type\"],\n",
    "        }\n",
    "        push_notebook(handle=handle)\n",
    "        time.sleep(0.2)\n",
    "        current_batch = {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"utm_x\": [d[\"utm_x\"] for d in data],\n",
    "            \"utm_y\": [d[\"utm_y\"] for d in data],\n",
    "            \"event_type\": [d[\"event_type\"] for d in data],\n",
    "        }\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "\n",
    "fg, source = create_map()\n",
    "\n",
    "# Updates\n",
    "handle = show(fg, notebook_handle=True)\n",
    "\n",
    "days_of_week = [\n",
    "    \"Monday\",\n",
    "    \"Tuesday\",\n",
    "    \"Wednesday\",\n",
    "    \"Thursday\",\n",
    "    \"Friday\",\n",
    "    \"Saturday\",\n",
    "    \"Sunday\",\n",
    "]\n",
    "\n",
    "data_source = temp.read(return_timestamp=False)\n",
    "time.sleep(5)\n",
    "for message in itertools.islice(data_source, 100):\n",
    "    data = message.data.data\n",
    "    index = data[0][\"group_id\"]\n",
    "    dt = datetime.utcfromtimestamp(index).replace(\n",
    "        tzinfo=pytz.UTC\n",
    "    )  # .astimezone(pytz.timezone('US/Eastern'))\n",
    "    dt_str = days_of_week[dt.weekday()] + \" \" + dt.strftime(\"%b %d %Y %I:%M:%S %p\")\n",
    "    fg.title.text = dt_str\n",
    "    fg.title.align = \"center\"\n",
    "    source.data = {\n",
    "        \"x\": [d[\"utm_x\"] for d in data],\n",
    "        \"y\": [d[\"utm_y\"] for d in data],\n",
    "        \"event_type\": [d[\"event_type\"] for d in data],\n",
    "    }\n",
    "    push_notebook(handle=handle)\n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "5zc3pwq0smN-"
   ],
   "name": "streambasedcache.ipynb",
   "provenance": [
    {
     "file_id": "14kD7KIsqpkuyVlvIKa4GUCOFXsMpiouh",
     "timestamp": 1561506409299
    },
    {
     "file_id": "1ZShzPcvbGP5mNaVb5xcjvR6r_QBkFyd6",
     "timestamp": 1561505940600
    },
    {
     "file_id": "https://github.com/ostrokach/beam-notebooks/blob/master/feature/filebasedcache.ipynb",
     "timestamp": 1561071440262
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
