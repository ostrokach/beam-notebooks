{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import os.path as op\n",
    "import queue\n",
    "\n",
    "import apache_beam as beam\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from apache_beam.runners.direct.direct_runner import BundleBasedDirectRunner\n",
    "from apache_beam.runners.interactive.cache_manager import (\n",
    "    FileBasedCacheManager, ReadCache, WriteCache)\n",
    "from apache_beam.runners.interactive.interactive_runner import \\\n",
    "    InteractiveRunner\n",
    "from apache_beam.runners.portability.fn_api_runner import FnApiRunner\n",
    "\n",
    "try:\n",
    "    from pathlib import Path\n",
    "except ImportError:\n",
    "    from pathlib2 import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"strokach-playground\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_NAME = \"interactive-beam-demo\"\n",
    "NOTEBOOK_PATH = Path(NOTEBOOK_NAME).resolve()\n",
    "NOTEBOOK_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "NOTEBOOK_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractiveSession(object):\n",
    "\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def _repr_html_(self):\n",
    "    return (\n",
    "        '<p style=\"padding-left: 1%; padding-right: 1%\">'\n",
    "        '<a href=\"'\n",
    "        'https://pantheon.corp.google.com/dataflow/jobsDetail/'\n",
    "        'locations/us-central1/'\n",
    "        'jobs/2019-05-30_14_39_33-6947614184630253675'\n",
    "        '\">Dashboard</a>'\n",
    "        '</p>'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Foo:\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self._in_context = True\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self._in_context = False\n",
    "        print(\"Exiting...!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = Foo()\n",
    "foo.__enter__()\n",
    "\n",
    "raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo._in_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b\"  ¡ ¢ £ ¤ ¥ ¦ § ¨ © ª « ¬ ­ ® ¯ ° ± ² ³ ´ µ ¶ · ¸ ¹ º » ¼ \".replace(b\" \", b\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parameterized import parameterized_class\n",
    "\n",
    "parameterized_class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with closing(np.random.randn(5,5)) as a:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = beam.runners.dataflow.DataflowRunner(\n",
    "    # interactive=True,\n",
    "    # timeout=\"30min\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = beam.pipeline.PipelineOptions(\n",
    "    project=PROJECT_ID,\n",
    "    job_name=NOTEBOOK_NAME,\n",
    "    temp_location=\"gs://strokach/dataflow_temp\",\n",
    "    staging_location=\"gs://strokach/dataflow_staging\",\n",
    "    sdk_location=op.expanduser(\n",
    "        \"~/workspace/beam/sdks/python/dist/apache-beam-2.14.0.dev0.tar.gz\"\n",
    "    ),\n",
    "#     timeout=600,\n",
    ")\n",
    "options.display_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_manager = FileBasedCacheManager(\n",
    "    cache_dir=\"gs://strokach/tmp\"\n",
    ")\n",
    "# atexit.register(cache_manager.cleanup) <- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.start_session(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with beam.Pipeline() as p:  # display=...\n",
    "    _ = (\n",
    "        #\n",
    "        p\n",
    "        | \"Read\" >> beam.io.ReadFromText(\"gs://strokach/inputs/winterstale\")\n",
    "        | \"Write\" >> WriteCache(cache_manager, \"temp\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "- `p.run()` should start the pipeline in the background, even in interactive mode. This makes sense for streaming, or when we want to start reading results as they appear.\n",
    "\n",
    "- There should be an option to display results while the pipeline is running. However, we should display results when we call `result.wait_until_finish()`, not when we call `p.run()`.\n",
    "\n",
    "- `result.wait_until_finish()` should not wait for the VM to shut down.\n",
    "\n",
    "- `WriteCache` should take an extra argument `format`, which allows the use to specify the format that will be used for writing the cache file. It should also be possible to pass additional arguments such as `schema=...`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The argument should be just \"temp\", and it should not return \"version\"\n",
    "data, _ = cache_manager.read(\"full\", \"temp\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data[0], columns=[\"string\"])\n",
    "\n",
    "df[\"string_clean\"] = df[\"string\"].str.strip()\n",
    "df[\"string_length\"] = df[\"string_clean\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg, ax = plt.subplots()\n",
    "\n",
    "_ = ax.hist(df[\"string_length\"])\n",
    "ax.set_xlabel(\"String length\")\n",
    "ax.set_ylabel(\"Number of strings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "- When we read from a `CacheManager`, we should not have to specify \"full\" or \"sample\". If the user so desires, they can provide that information in the name that they give to their cache object.\n",
    "\n",
    "- `CacheManager.read(...)` should not return the cache version by default. It should be assumeed that we are always reading the latest cache object.\n",
    "\n",
    "- `CacheManager.read(...)` should have a `limit=...` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying cache using Beam SQL, BigQuery, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until we have a Python frontend for Beam SQL, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing cached objects using DirectRunner\n",
    "\n",
    "For simple types of queries that are likely to be limited by I/O, it may be helpful to explore the data using `DirectRunner`. Furthermore, we might want to store the output directly in memory instead of saving it to a file. Both the `BundleBasedDirectRunner` and the `FnApiRunner` run workers inside Python threads, so the results can simply be passed into a `queue.Queue()`. If `DirectRunner` ever switches to using `multiprocessing` ([BEAM-1442](https://issues.apache.org/jira/browse/BEAM-1442)), a more sophisticated way of transfering data between processes may be required. For example, PyTorch creates memory-mapped files, and passes filehandes to those files between processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apache_beam.typehints import typehints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typehints.Union[[str, int, int, str]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(\"A\", typehints.TypeConstraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = queue.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_queue(element, queue):\n",
    "    queue.put(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = Par"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typehints.Union[[int, int, str, None]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    typehints.Union[int, str, str]: 'a'\n",
    "}[typehints.Union[int, str, int]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typehints.normalize(b\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from past.builtins import unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa.array([[1,2,3], [4,5,6], [1.3, 4.5]]).type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa.int64()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  _typehint_to_avro_type = {\n",
    "      typehints.Union[[int]]: \"int\",\n",
    "#       typehints.Union[int, None]: [\"int\", \"null\"],\n",
    "#       typehints.Union[long]: \"long\",\n",
    "#       typehints.Union[long, None]: [\"long\", \"null\"],\n",
    "#       typehints.Union[float]: \"double\",\n",
    "#       typehints.Union[float, None]: [\"double\", \"null\"],\n",
    "#       typehints.Union[str]: \"string\",\n",
    "#       typehints.Union[str, None]: [\"string\", \"null\"],\n",
    "#       typehints.Union[unicode]: \"string\",\n",
    "#       typehints.Union[unicode, None]: [\"string\", \"null\"],\n",
    "#       typehints.Union[np.ndarray]: \"bytes\",\n",
    "#       typehints.Union[np.ndarray, None]: [\"bytes\", \"null\"],\n",
    "#       typehints.Union[array.array]: \"bytes\",\n",
    "#       typehints.Union[array.array, None]: [\"bytes\", \"null\"],\n",
    "#   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import avro.schema\n",
    "from avro.datafile import DataFileReader, DataFileWriter\n",
    "from avro.io import DatumReader, DatumWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_dict = {\"namespace\": \"example.avro\",\n",
    " \"type\": \"record\",\n",
    " \"name\": \"User\",\n",
    " \"fields\": [\n",
    "     {\"name\": \"name\", \"type\": \"string\"},\n",
    "     {\"name\": \"favorite_number\",  \"type\": [\"int\", \"null\"]},\n",
    "     {\"name\": \"favorite_color\", \"type\": [\"string\", \"null\"]}\n",
    " ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avro.schema.parse(json.dumps(schema_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mock import MagicMock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = MagicMock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer(a=1, b=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(writer.call_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.writer._sink.write_record.side_effect = Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.writer._sink.write_record(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.reader.call_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apache_beam.typehints import trivial_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trivial_inference.instance_to_type("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u\"±♠Ωℑ\".encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b\"±♠Ωℑ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = array.array('i', [10,20,30,40,50])\n",
    "array1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = queue.Queue()\n",
    "\n",
    "with beam.Pipeline(runner=BundleBasedDirectRunner()) as p:\n",
    "    _ = (\n",
    "        #\n",
    "        p\n",
    "        | \"Read\" >> ReadCache(cache_manager, \"temp\")\n",
    "        | \"Remove whitespace\" >> beam.Map(lambda element: element.strip(\"\\n\\t|\"))\n",
    "        | \"Remove empty lines\" >> beam.FlatMap(lambda element: [element] if element else [])\n",
    "        | \"Write\" >> beam.Map(lambda element: add_to_queue(element, queue=q))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = beam.Pipeline(runner=BundleBasedDirectRunner())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p | \"Read\" >> ReadCache(cache_manager, \"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p | \"ass\" >> beam.Map(lambda element: element.strip(\"\\n\\t|\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p | \"ass\" >> beam.Map(lambda element: element.strip(\"\\n\\t|\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(q.queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg, ax = plt.subplots()\n",
    "\n",
    "_ = ax.hist([len(s) for s in data])\n",
    "ax.set_title(\"Number of strings after removing whitespace\")\n",
    "ax.set_xlabel(\"String length\")\n",
    "ax.set_ylabel(\"Number of strings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "- It may be useful to have a well-defined class for outputing results to an object in the main process. That way, if the implementation of `DirectRunner` changes, this way of accessing results could remain backwards-compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = beam.io.textio.ReadFromText(\"gs://strokach/inputs/winterstale\")\n",
    "range_tracker = reader._source.get_range_tracker(None, None)\n",
    "data = list(reader._source.read(range_tracker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_manager.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runner.__exit__()\n",
    "# runner.end_session() (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
