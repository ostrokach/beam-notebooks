{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bYniTY18yHx2"
   },
   "source": [
    "# StreamBasedCache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUtedcvxeXG1"
   },
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFU0y74LKkZz"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    GOOGLE_COLAB = True\n",
    "except ImportError:\n",
    "    GOOGLE_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vwc8s3ZMviEy"
   },
   "outputs": [],
   "source": [
    "if GOOGLE_COLAB:\n",
    "    !sudo apt-get -yqq install libsnappy-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6JBBvTSgvcoD"
   },
   "outputs": [],
   "source": [
    "if GOOGLE_COLAB:\n",
    "    !pip install -q python-snappy Faker pyproj\n",
    "    !pip install -q -U bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9938,
     "status": "ok",
     "timestamp": 1561509815353,
     "user": {
      "displayName": "Alexey Strokach",
      "photoUrl": "https://lh4.googleusercontent.com/-CsQDBBcl3n0/AAAAAAAAAAI/AAAAAAAACyg/LJXILPSVwok/s64/photo.jpg",
      "userId": "14295043229009166910"
     },
     "user_tz": 420
    },
    "id": "zsUWt2AjsmWU",
    "outputId": "b2f917a3-9f89-4317-8a40-4e501de2415d"
   },
   "outputs": [],
   "source": [
    "if GOOGLE_COLAB:\n",
    "    !pip install \"git+https://github.com/ostrokach/beam.git@feature/streambasedcache#egg=apache_beam[gcp]&subdirectory=sdks/python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5zc3pwq0smN-"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EwceiH15eVt-"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import requests\n",
    "import tqdm\n",
    "from faker import Faker\n",
    "from google.api_core import exceptions as gexc\n",
    "from google.cloud import pubsub\n",
    "\n",
    "import apache_beam as beam\n",
    "import pyproj\n",
    "from apache_beam.io.filesystems import FileSystems\n",
    "from apache_beam.io.gcp.pubsub import PubsubMessage\n",
    "from apache_beam.options.pipeline_options import GoogleCloudOptions\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.runners.direct.direct_runner import BundleBasedDirectRunner\n",
    "from apache_beam.runners.interactive import caching\n",
    "from apache_beam.transforms import combiners\n",
    "from apache_beam.transforms import window\n",
    "from apache_beam.transforms.ptransform import ptransform_fn\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.io import push_notebook\n",
    "from bokeh.io import show\n",
    "from bokeh.layouts import row\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hzzEnIEftMYZ"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GOOGLE_COLAB:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10345,
     "status": "ok",
     "timestamp": 1561509815816,
     "user": {
      "displayName": "Alexey Strokach",
      "photoUrl": "https://lh4.googleusercontent.com/-CsQDBBcl3n0/AAAAAAAAAAI/AAAAAAAACyg/LJXILPSVwok/s64/photo.jpg",
      "userId": "14295043229009166910"
     },
     "user_tz": 420
    },
    "id": "IpuqYM-zsorD",
    "outputId": "28d072f4-bafc-483f-98e3-931be526e177"
   },
   "outputs": [],
   "source": [
    "#@title Google Cloud Project Info { display-mode: \"form\" }\n",
    "project_id = \"strokach-playground\" #@param {type:\"string\"}\n",
    "gcs_temp_location = \"gs://strokach/dataflow_temp\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_NAME = \"streambasedcache_chicago\"\n",
    "try:\n",
    "    os.mkdir(NOTEBOOK_NAME)\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10315,
     "status": "ok",
     "timestamp": 1561509815817,
     "user": {
      "displayName": "Alexey Strokach",
      "photoUrl": "https://lh4.googleusercontent.com/-CsQDBBcl3n0/AAAAAAAAAAI/AAAAAAAACyg/LJXILPSVwok/s64/photo.jpg",
      "userId": "14295043229009166910"
     },
     "user_tz": 420
    },
    "id": "Y2KieHGYrOKY",
    "outputId": "3ed360d6-651a-4477-eb12-5a7cab5bd4c8"
   },
   "outputs": [],
   "source": [
    "options = PipelineOptions(\n",
    "    temp_location=gcs_temp_location, streaming=True, project=project_id\n",
    ")\n",
    "options.display_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "except Exception:\n",
    "    print(\"No autoreload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, outfile):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    return local_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    chicago_taxi_trips_2018_12 = pd.read_csv(\"chicago_taxi_trips_2018_12.csv.gz\")\n",
    "except OSError:\n",
    "    local_filename = download_file(\"https://storage.googleapis.com/strokach/inputs/chicago_taxi_trips_2018_12.csv.gz\")\n",
    "    chicago_taxi_trips_2018_12 = pd.read_csv(local_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    chicago_taxi_trips_2019_01 = pd.read_csv(\"chicago_taxi_trips_2019_01.csv.gz\")\n",
    "except IOError:\n",
    "    local_filename = download_file(\"https://storage.googleapis.com/strokach/inputs/chicago_taxi_trips_2019_01.csv.gz\")\n",
    "    chicago_taxi_trips_2019_01 = pd.read_csv(local_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that latilatitude and longitude columns have the same info as location columns\n",
    "df1 = chicago_taxi_trips_2018_12[\n",
    "    (~chicago_taxi_trips_2018_12[[\"pickup_location\", \"dropoff_location\"]].isnull().any(axis=1))\n",
    "]\n",
    "\n",
    "df2 = chicago_taxi_trips_2018_12[\n",
    "    (~chicago_taxi_trips_2018_12[[\"pickup_latitude\", \"pickup_longitude\", \"dropoff_latitude\", \"dropoff_longitude\"]].isnull().any(axis=1))\n",
    "]\n",
    "\n",
    "assert (df1.index == df2.index).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that latilatitude and longitude columns have the same info as location columns\n",
    "df1 = chicago_taxi_trips_2019_01[\n",
    "    (~chicago_taxi_trips_2019_01[[\"pickup_location\", \"dropoff_location\"]].isnull().any(axis=1))\n",
    "]\n",
    "\n",
    "df2 = chicago_taxi_trips_2019_01[\n",
    "    (~chicago_taxi_trips_2019_01[[\"pickup_latitude\", \"pickup_longitude\", \"dropoff_latitude\", \"dropoff_longitude\"]].isnull().any(axis=1))\n",
    "]\n",
    "\n",
    "assert (df1.index == df2.index).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `events_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonull_columns = [\n",
    "    \"pickup_latitude\",\n",
    "    \"pickup_longitude\",\n",
    "    \"dropoff_latitude\",\n",
    "    \"dropoff_longitude\",\n",
    "]\n",
    "\n",
    "events = []\n",
    "\n",
    "for i, row in enumerate(\n",
    "    itertools.chain(\n",
    "        chicago_taxi_trips_2018_12[\n",
    "            chicago_taxi_trips_2018_12[nonull_columns].notnull().all(axis=1)\n",
    "        ].itertuples(),\n",
    "        chicago_taxi_trips_2019_01[\n",
    "            chicago_taxi_trips_2019_01[nonull_columns].notnull().all(axis=1)\n",
    "        ].itertuples(),\n",
    "    )\n",
    "):\n",
    "    start_event = {\n",
    "        \"index\": i,\n",
    "        \"event_type\": \"start\",\n",
    "        \"unique_key\": row.unique_key,\n",
    "        \"taxi_id\": row.taxi_id,\n",
    "        \"timestamp\": row.trip_start_timestamp,\n",
    "        \"latitude\": row.pickup_latitude,\n",
    "        \"longitude\": row.pickup_longitude,\n",
    "    }\n",
    "\n",
    "    stop_event = {\n",
    "        \"index\": i,\n",
    "        \"event_type\": \"stop\",\n",
    "        \"unique_key\": row.unique_key,\n",
    "        \"taxi_id\": row.taxi_id,\n",
    "        \"timestamp\": row.trip_end_timestamp,\n",
    "        \"latitude\": row.dropoff_latitude,\n",
    "        \"longitude\": row.dropoff_longitude,\n",
    "        \"trip_seconds\": row.trip_seconds,\n",
    "        \"trip_miles\": row.trip_miles,\n",
    "        \"trip_total\": row.trip_total,\n",
    "    }\n",
    "\n",
    "    events.extend([start_event, stop_event])\n",
    "\n",
    "\n",
    "events_columns = [\n",
    "    \"index\",\n",
    "    \"event_type\",\n",
    "    \"unique_key\",\n",
    "    \"taxi_id\",\n",
    "    \"timestamp\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"trip_seconds\",\n",
    "    \"trip_miles\",\n",
    "    \"trip_total\",\n",
    "]\n",
    "events_df = pd.DataFrame(events, columns=events_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = Counter([tuple(ll) for ll in events_df[[\"latitude\", \"longitude\"]].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.DataFrame([key + (value,) for key, value in c.items()], columns=[\"latitude\", \"longitude\", \"count\"]).sort_values(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.clip(counts[\"count\"], 0, 100), range=(0, 100), bins=50)\n",
    "plt.xlabel(\"Number of pickups / drop-offs in location\\n(Capped at 100)\")\n",
    "plt.ylabel(\"Number of locations\")\n",
    "plt.title(\"Chicago - December 2018 / January 2019\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add `timestamp_seconds` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_to_seconds(timestamp_str):\n",
    "    from datetime import datetime\n",
    "    import pytz\n",
    "\n",
    "    dt = datetime.strptime(timestamp_str, \"%Y-%m-%d %H:%M:%S UTC\")\n",
    "    dt = dt.replace(tzinfo=pytz.UTC)  # .astimezone(pytz.timezone('America/Chicago'))\n",
    "    unix_dt = datetime.utcfromtimestamp(0).replace(tzinfo=pytz.UTC)\n",
    "    dt_delta = (dt - unix_dt).total_seconds()\n",
    "    return dt_delta\n",
    "\n",
    "timestamp_to_seconds(\"2018-12-06 00:00:00 UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df[\"timestamp_seconds\"] = events_df[\"timestamp\"].apply(timestamp_to_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df[\"utm_x\"], events_df[\"utm_y\"] = list(\n",
    "    zip(\n",
    "        *[\n",
    "            geographic_to_utm(*ll)\n",
    "            for ll in tqdm.tqdm_notebook(\n",
    "                events_df[[\"longitude\", \"latitude\"]].values, total=len(events_df)\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = events_df.sort_values(\"timestamp_seconds\", ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_timestamp(timestamp_str):\n",
    "    from datetime import datetime\n",
    "\n",
    "    dt = datetime.strptime(timestamp_str, \"%Y-%m-%d %H:%M:%S UTC\")\n",
    "    dt = dt.replace(tzinfo=pytz.UTC).astimezone(pytz.timezone('America/Chicago'))\n",
    "    return dt\n",
    "\n",
    "expand_timestamp(\"2018-12-06 00:00:00 UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geographic_to_utm(longitude, latitude, _cache={}):\n",
    "    if (longitude, latitude) in _cache:\n",
    "        return _cache[(longitude, latitude)]\n",
    "\n",
    "    from pyproj import Proj, transform\n",
    "\n",
    "    x, y = transform(\n",
    "        Proj(init=\"epsg:4326\"), Proj(init=\"epsg:3857\"), longitude, latitude\n",
    "    )\n",
    "\n",
    "    _cache[(longitude, latitude)] = (x, y)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "geographic_to_utm(-87.632746, 41.880994)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JHv-dElW8IN9"
   },
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "from bokeh.layouts import row\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.tile_providers import Vendors, get_provider\n",
    "from bokeh.models.annotations import Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LONGITUDE_RANGE = events_df[\"longitude\"].min(), events_df[\"longitude\"].max()\n",
    "LATITUDE_RANGE = events_df[\"latitude\"].min(), events_df[\"latitude\"].max()\n",
    "\n",
    "x_min, y_min = geographic_to_utm(longitude=LONGITUDE_RANGE[0], latitude=LATITUDE_RANGE[0])\n",
    "x_max, y_max = geographic_to_utm(longitude=LONGITUDE_RANGE[1], latitude=LATITUDE_RANGE[1])\n",
    "\n",
    "MERCATOR_X_RANGE = (x_min, x_max)\n",
    "MERCATOR_Y_RANGE = (y_min, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook\n",
    "from bokeh.io import push_notebook\n",
    "from bokeh.io import show\n",
    "from bokeh.layouts import row\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.models import Label\n",
    "from bokeh.models import LabelSet\n",
    "from bokeh.models import Range1d\n",
    "from bokeh.models.annotations import Title\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.plotting import output_file\n",
    "from bokeh.plotting import show\n",
    "from bokeh.tile_providers import Vendors\n",
    "from bokeh.tile_providers import get_provider\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "if GOOGLE_COLAB:\n",
    "    print(\"Interactive plot does not work on colab yet!\")\n",
    "\n",
    "# range bounds supplied in web mercator coordinates\n",
    "fig = figure(\n",
    "    x_range=MERCATOR_X_RANGE,\n",
    "    y_range=MERCATOR_Y_RANGE,\n",
    "    x_axis_type=\"mercator\",\n",
    "    y_axis_type=\"mercator\",\n",
    "    #     title_location=\"left\"\n",
    "    #     plot_height=600,\n",
    ")\n",
    "fig.add_tile(get_provider(Vendors.CARTODBPOSITRON))\n",
    "\n",
    "source = ColumnDataSource(data=dict(x=[], y=[]))\n",
    "\n",
    "fig.circle(x=\"x\", y=\"y\", size=2, fill_color=\"blue\", fill_alpha=0.8, source=source)\n",
    "\n",
    "handle = show(fig, notebook_handle=True)\n",
    "\n",
    "for index, gp in events_df.sample(frac=0.1).groupby([\"timestamp\"]):\n",
    "    print(index)\n",
    "    print('0')\n",
    "    gp = gp.copy()\n",
    "    print('1')\n",
    "    gp[\"utm_x\"], gp[\"utm_y\"] = list(\n",
    "        zip(*[geographic_to_utm(*ll) for ll in gp[[\"longitude\", \"latitude\"]].values])\n",
    "    )\n",
    "    print('a')\n",
    "    fig.title.text = index\n",
    "    fig.title.align = \"center\"\n",
    "    print('b')\n",
    "    source.data = {\"x\": gp[\"utm_x\"].values, \"y\": gp[\"utm_y\"].values}\n",
    "    print('c')\n",
    "    push_notebook(handle=handle)\n",
    "#     time.sleep(1)\n",
    "#     break\n",
    "\n",
    "# while True:\n",
    "#     for i, row in enumerate(temp.read()):\n",
    "#         title = Title()\n",
    "#         title.text = row[0].strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "#         fig.title = title\n",
    "#         source.stream({\"x\": [e[\"x\"] for e in row[1]], \"y\": [e[\"y\"] for e in row[1]]})\n",
    "#         push_notebook(handle=handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write dataset to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_client = pubsub.SubscriberClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_name = \"projects/{}/subscriptions/taxirides-realtime-sub\".format(project_id)\n",
    "\n",
    "try:\n",
    "    sub_client.create_subscription(\n",
    "        subscription_name,\n",
    "        \"projects/pubsub-public-data/topics/taxirides-realtime\",\n",
    "    )\n",
    "except gexc.AlreadyExists:\n",
    "    sub_client.delete_subscription(subscription_name)\n",
    "    sub_client.create_subscription(\n",
    "        subscription_name,\n",
    "        \"projects/pubsub-public-data/topics/taxirides-realtime\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data from subscription to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LONGITUDE_RANGE = (-74.747, -73.969)  # (-74.07, -73.90)\n",
    "LATITUDE_RANGE = (40.699, 40.720)  # (40.73, 40.77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, y_min = geographic_to_utm(longitude=LONGITUDE_RANGE[0], latitude=LATITUDE_RANGE[0])\n",
    "x_max, y_max = geographic_to_utm(longitude=LONGITUDE_RANGE[1], latitude=LATITUDE_RANGE[1])\n",
    "\n",
    "MERCATOR_X_RANGE = (x_min, x_max)\n",
    "MERCATOR_Y_RANGE = (y_min, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    p_result.cancel()\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = caching.PubSubBasedCache(\n",
    "    \"projects/{}/topics/temp-2\".format(project_id), mode=\"overwrite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToList(beam.PTransform):\n",
    "  \"\"\"A global CombineFn that condenses a PCollection into a single list.\"\"\"\n",
    "\n",
    "  def __init__(self, label='ToList'):  # pylint: disable=useless-super-delegation\n",
    "    super(ToList, self).__init__(label)\n",
    "\n",
    "  def expand(self, pcoll):\n",
    "    return pcoll | self.label >> beam.CombineGlobally(combiners.ToListCombineFn()).without_defaults()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildRecordFn(beam.DoFn):\n",
    "    def __init__(self):\n",
    "        super(BuildRecordFn, self).__init__()\n",
    "\n",
    "    def process(self, elements, window=beam.DoFn.WindowParam):\n",
    "        # window_start = window.start.to_utc_datetime()\n",
    "        window_end = window.end.to_utc_datetime()\n",
    "        return [(window_end, elements)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = beam.Pipeline(runner=BundleBasedDirectRunner(), options=options)\n",
    "\n",
    "out = (\n",
    "    p\n",
    "    | \"Read\" >> beam.io.ReadFromPubSub(subscription=subscription_name, with_attributes=True)\n",
    "#     | \"echo\" >> beam.Map(lambda e: print(e) or e)\n",
    "    | \"Decode PubSub message\" >> beam.ParDo(DecodeTaxiMessage())\n",
    "    | \"Load JSON\" >> beam.Map(load_json)\n",
    "    | \"Filter coords\" >> beam.ParDo(SelectWithinGeographicRange(LONGITUDE_RANGE, LATITUDE_RANGE))\n",
    "    | \"Add UTM coords\" >> beam.Map(add_mercator_coords)\n",
    "    | \"Window\" >> beam.WindowInto(window.FixedWindows(2 * 60))\n",
    "    | \"Combine\" >> ToList()\n",
    "    | 'AddWindowEndTimestamp' >> beam.ParDo(BuildRecordFn())\n",
    "#     | \"echo\" >> beam.Map(lambda e: print(e) or e)\n",
    "    | \"Write\" >> temp.writer()\n",
    ")\n",
    "\n",
    "p_result = p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in itertools.islice(temp.read(), 2):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row[0].strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.getLogger(\"google.auth._default\").setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "from bokeh.layouts import row\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.tile_providers import Vendors, get_provider\n",
    "from bokeh.models.annotations import Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "\n",
    "if GOOGLE_COLAB:\n",
    "    print(\"Interactive plot does not work on colab yet!\")\n",
    "\n",
    "# range bounds supplied in web mercator coordinates\n",
    "fig = figure(\n",
    "    x_range=MERCATOR_X_RANGE,\n",
    "    y_range=MERCATOR_Y_RANGE,\n",
    "    x_axis_type=\"mercator\",\n",
    "    y_axis_type=\"mercator\",\n",
    "#     plot_height=600,\n",
    ")\n",
    "fig.add_tile(get_provider(Vendors.CARTODBPOSITRON))\n",
    "\n",
    "source = ColumnDataSource(data=dict(x=[], y=[]))\n",
    "\n",
    "fig.circle(x=\"x\", y=\"y\", size=2, fill_color=\"blue\", fill_alpha=0.8, source=source)\n",
    "\n",
    "handle = show(fig, notebook_handle=True)\n",
    "\n",
    "while True:\n",
    "    for i, row in enumerate(temp.read()):\n",
    "        title = Title()\n",
    "        title.text = row[0].strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fig.title = title\n",
    "        source.stream({\"x\": [e[\"x\"] for e in row[1]], \"y\": [e[\"y\"] for e in row[1]]})\n",
    "        push_notebook(handle=handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "5zc3pwq0smN-"
   ],
   "name": "streambasedcache.ipynb",
   "provenance": [
    {
     "file_id": "14kD7KIsqpkuyVlvIKa4GUCOFXsMpiouh",
     "timestamp": 1561506409299
    },
    {
     "file_id": "1ZShzPcvbGP5mNaVb5xcjvR6r_QBkFyd6",
     "timestamp": 1561505940600
    },
    {
     "file_id": "https://github.com/ostrokach/beam-notebooks/blob/master/feature/filebasedcache.ipynb",
     "timestamp": 1561071440262
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
